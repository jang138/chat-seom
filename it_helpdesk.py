import streamlit as st
import json
import os
from dotenv import load_dotenv
from langchain_upstage import ChatUpstage, UpstageEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from keywords import (
    GREETING_KEYWORDS,
    CASUAL_KEYWORDS,
    OFFTOPIC_KEYWORDS,
    WITTY_KEYWORDS,
)

load_dotenv()


def classify(user_input, api_key):
    chat = ChatUpstage(api_key=api_key, model="solar-mini")

    prompt = f"""ë‹¹ì‹ ì€ IT í—¬í”„ë°ìŠ¤í¬ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë¬¸ì˜ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë¶„ë¥˜ë¥¼ ê²°ì •í•˜ì„¸ìš”.

**ë¶„ë¥˜ ê¸°ì¤€:**

1. **existing** - ì¼ë°˜ì ì¸ IT ë¬¸ì œ (ê¸°ì¡´ FAQ/ë§¤ë‰´ì–¼ ìˆìŒ)
   - ë„¤íŠ¸ì›Œí¬, ê³„ì •, ì´ë©”ì¼, í•˜ë“œì›¨ì–´, ì†Œí”„íŠ¸ì›¨ì–´ ë“± í”í•œ ë¬¸ì œ
   - ì˜ˆ: "ì™€ì´íŒŒì´ ì•ˆë¨", "ë¹„ë°€ë²ˆí˜¸ ìŠìŒ", "í”„ë¦°í„° ì˜¤ë¥˜"

2. **new** - ìƒˆë¡­ì§€ë§Œ ê°€ì¹˜ ìˆëŠ” IT ì§ˆë¬¸
   - ë‹¤ë¥¸ ì§ì›ë“¤ë„ ê¶ê¸ˆí•´í•  ë§Œí•œ ìƒˆë¡œìš´ ê¸°ìˆ /ì •ì±…/ë„êµ¬ ê´€ë ¨
   - ì˜ˆ: "ìƒˆë¡œìš´ í˜‘ì—…ë„êµ¬ ì‚¬ìš©ë²•", "ìµœì‹  ë³´ì•ˆ ì •ì±…", "ì‹ ê·œ ì‹œìŠ¤í…œ"

3. **skip** - FAQ ê°€ì¹˜ ì—†ëŠ” ì§ˆë¬¸
   - ì¸ì‚¬, ê°ì‚¬, ì¼ë°˜ ëŒ€í™”, IT ë¬´ê´€í•œ ì§ˆë¬¸
   - ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”", "ê°ì‚¬í•©ë‹ˆë‹¤", "ì ì‹¬ ë©”ë‰´", "íšŒì˜ì‹¤ ì˜ˆì•½"

**ì¤‘ìš”**: ë‹¤ë¥¸ ì§ì›ë“¤ë„ ê¶ê¸ˆí•´í•  ë§Œí•œ IT ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.

ë¬¸ì˜: {user_input}

ë¶„ë¥˜: """

    result = chat.invoke(
        [
            SystemMessage(
                content="ë‹¹ì‹ ì€ IT í—¬í”„ë°ìŠ¤í¬ì˜ ë² í…Œë‘ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì •í™•í•œ ë¬¸ì œ ë¶„ë¥˜ì™€ ì¹œì ˆí•œ ê³ ê° ì‘ëŒ€ë¥¼ ë™ì‹œì— ìˆ˜í–‰í•©ë‹ˆë‹¤."
            ),
            HumanMessage(content=prompt),
        ]
    )

    classification = result.content.strip()

    # ë¶„ë¥˜ ê²°ê³¼ ì •ë¦¬
    if "existing" in classification:
        return "existing"
    elif "new" in classification:
        return "new"
    elif "skip" in classification:
        return "skip"
    else:
        return "skip"


def answer(user_input, chat_history, category, api_key):
    chat = ChatUpstage(api_key=api_key, model="solar-pro")
    embeddings = UpstageEmbeddings(api_key=api_key, model="solar-embedding-1-large")

    db = Chroma(persist_directory="chroma_db", embedding_function=embeddings)

    # if db._collection.count() == 0:
    #     load_manual(db)

    retriever = db.as_retriever(search_kwargs={"k": 3})

    # ì§ˆë¬¸ ì¬êµ¬ì„±
    ctx_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", "ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•˜ì„¸ìš”."),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    hist_retriever = create_history_aware_retriever(chat, retriever, ctx_prompt)

    # ë‹µë³€ ìƒì„±
    qa_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                f"""IT í—¬í”„ë°ìŠ¤í¬ì…ë‹ˆë‹¤. ë¶„ë¥˜: {category}

        ê·œì¹™:
        1. ë§¤ë‰´ì–¼ ì •ë³´ í™œìš©
        2. ëª¨ë¥´ë©´ IT ê´€ë¦¬ì ì—°ê²°
        3. ë‹¨ê³„ë³„ ì„¤ëª…

        ì§€ì› ì˜ì—­: ë„¤íŠ¸ì›Œí¬, ê³„ì •, ì´ë©”ì¼, í•˜ë“œì›¨ì–´, ì†Œí”„íŠ¸ì›¨ì–´, ë³´ì•ˆ

        ì°¸ê³ : {{context}}""",
            ),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    qa_chain = create_stuff_documents_chain(chat, qa_prompt)
    rag_chain = create_retrieval_chain(hist_retriever, qa_chain)

    # íˆìŠ¤í† ë¦¬ ë³€í™˜
    history = []
    for msg in chat_history:
        if msg["role"] == "user":
            history.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            history.append(AIMessage(content=msg["content"]))

    result = rag_chain.invoke({"input": user_input, "chat_history": history})
    return result["answer"]


def load_manual(db):
    with open("it_helpdesk_manual.json", "r", encoding="utf-8") as f:
        data = json.load(f)

    docs = []
    for item in data:
        doc = Document(
            page_content=item["text_content"],
            metadata={
                "id": item["id"],
                "category": item["metadata"]["category"],
                "scenario": item["metadata"]["scenario"],
                "keywords": ", ".join(item["metadata"]["keywords"]),
                "priority": item["metadata"]["priority"],
            },
        )
        docs.append(doc)

    db.add_documents(docs)
    print(f"{len(docs)}ê°œ ë¬¸ì„œ ë²¡í„° DBì— ì¶”ê°€ ì™„ë£Œ")


def get_response(user_input, chat_history, api_key):
    category = classify(user_input, api_key)
    response = answer(user_input, chat_history, category, api_key)
    return response


@st.cache_resource
def init_db():
    """ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ëŠ” DB ì´ˆê¸°í™”"""
    api_key = os.getenv("UPSTAGE_API_KEY")
    if not api_key:
        print("API KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    embeddings = UpstageEmbeddings(api_key=api_key, model="solar-embedding-1-large")
    db = Chroma(persist_directory="chroma_db", embedding_function=embeddings)

    if db._collection.count() == 0:
        load_manual(db)
        print("âœ… ë§¤ë‰´ì–¼ ë¡œë”© ì™„ë£Œ!")
    else:
        print("âœ… ê¸°ì¡´ ë§¤ë‰´ì–¼ ë°ì´í„° ë¡œë”© ì™„ë£Œ")

    return db


# UI ì‹œì‘ ë¶€ë¶„
st.set_page_config(page_title="IT í—¬í”„ë°ìŠ¤í¬", page_icon="ğŸ’»")

if "messages" not in st.session_state:
    st.session_state.messages = []

if "api_key" not in st.session_state:
    st.session_state.api_key = os.getenv("UPSTAGE_API_KEY")

if st.session_state.api_key:
    db = init_db()
    if db is None:
        st.error("ë§¤ë‰´ì–¼ ë¡œë”© ì‹¤íŒ¨")

st.title("ğŸ’» IT í—¬í”„ë°ìŠ¤í¬")

if not st.session_state.api_key:
    st.warning("API í‚¤ í•„ìš”")
    api_key = st.text_input("API í‚¤:", type="password")
    if api_key:
        st.session_state.api_key = api_key
        st.rerun()

# ì²« ì¸ì‚¬ ë©”ì‹œì§€
if not st.session_state.messages:
    greeting = """IT í—¬í”„ë°ìŠ¤í¬ì…ë‹ˆë‹¤. ğŸ’»

    ì§€ì› ê°€ëŠ¥:
    ğŸŒ ë„¤íŠ¸ì›Œí¬ (ì™€ì´íŒŒì´, VPN)
    ğŸ” ê³„ì •/ë¡œê·¸ì¸
    ğŸ“§ ì´ë©”ì¼/ì—…ë¬´ì‹œìŠ¤í…œ
    ğŸ–¨ï¸ í•˜ë“œì›¨ì–´
    ğŸ’¿ ì†Œí”„íŠ¸ì›¨ì–´
    ğŸ›¡ï¸ ë³´ì•ˆ

    ë¬¸ì œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

    st.session_state.messages.append({"role": "assistant", "content": greeting})

# ì±„íŒ… ë¶€ë¶„
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ë¬¸ì œ ì„¤ëª…"):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response = get_response(
            prompt, st.session_state.messages[:-1], st.session_state.api_key
        )
        st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})
