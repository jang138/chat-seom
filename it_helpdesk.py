__import__("pysqlite3")
import sys

sys.modules["sqlite3"] = sys.modules.pop("pysqlite3")

import streamlit as st
import json
import os
from dotenv import load_dotenv
from datetime import datetime
from langchain_upstage import ChatUpstage, UpstageEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from faq_manager import save_faq_candidates, load_faq_candidates, add_faq_candidate
from keywords import (
    GREETING_KEYWORDS,
    CASUAL_KEYWORDS,
    OFFTOPIC_KEYWORDS,
    CASUAL_CHAT_KEYWORDS,
)

load_dotenv()

# streamlit secrets ì‚¬ìš© ì‹œ í™œì„±í™”
# os.environ["UPSTAGE_API_KEY"] = st.secrets["UPSTAGE_API_KEY"]


def classify(user_input, api_key):

    # # 1. ë¨¼ì € ChromaDBì—ì„œ ìœ ì‚¬í•œ FAQ ê²€ìƒ‰
    # embeddings = UpstageEmbeddings(api_key=api_key, model="solar-embedding-1-large")
    # db = Chroma(persist_directory="chroma_db", embedding_function=embeddings)

    # results = db.similarity_search(user_input, k=1)

    # # 2. ìœ ì‚¬ë„ê°€ ë†’ìœ¼ë©´ existingìœ¼ë¡œ ë¶„ë¥˜
    # if results and results[0].metadata.get("type") in [
    #     "approved_faq",
    #     "user_generated_faq",
    # ]:
    #     return "existing"

    chat = ChatUpstage(api_key=api_key, model="solar-mini")

    prompt = f"""ë‹¹ì‹ ì€ IT í—¬í”„ë°ìŠ¤í¬ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ë¬¸ì˜ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë¶„ë¥˜ë¥¼ ê²°ì •í•˜ì„¸ìš”.

        **ë¶„ë¥˜ ê¸°ì¤€:**

        1. **existing** - ì¼ë°˜ì ì¸ IT ë¬¸ì œ (ê¸°ì¡´ FAQ/ë§¤ë‰´ì–¼ ìˆìŒ)
        - ë„¤íŠ¸ì›Œí¬, ê³„ì •, ì´ë©”ì¼, í•˜ë“œì›¨ì–´, ì†Œí”„íŠ¸ì›¨ì–´ ë“± í”í•œ ë¬¸ì œ
        - ì˜ˆ: "ì™€ì´íŒŒì´ ì•ˆë¨", "ë¹„ë°€ë²ˆí˜¸ ìŠìŒ", "í”„ë¦°í„° ì˜¤ë¥˜"

        2. **new** - ìƒˆë¡­ì§€ë§Œ ê°€ì¹˜ ìˆëŠ” IT ì§ˆë¬¸
        - ë‹¤ë¥¸ ì§ì›ë“¤ë„ ê¶ê¸ˆí•´í•  ë§Œí•œ ìƒˆë¡œìš´ ê¸°ìˆ /ì •ì±…/ë„êµ¬ ê´€ë ¨
        - ì˜ˆ: "ìƒˆë¡œìš´ í˜‘ì—…ë„êµ¬ ì‚¬ìš©ë²•", "ìµœì‹  ë³´ì•ˆ ì •ì±…", "ì‹ ê·œ ì‹œìŠ¤í…œ"

        3. **skip** - FAQ ê°€ì¹˜ ì—†ëŠ” ì§ˆë¬¸
        - ì¸ì‚¬, ê°ì‚¬, ì¼ë°˜ ëŒ€í™”, IT ë¬´ê´€í•œ ì§ˆë¬¸
        - ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”", "ê°ì‚¬í•©ë‹ˆë‹¤", "ì ì‹¬ ë©”ë‰´", "íšŒì˜ì‹¤ ì˜ˆì•½"

        **ì¤‘ìš”**: ë‹¤ë¥¸ ì§ì›ë“¤ë„ ê¶ê¸ˆí•´í•  ë§Œí•œ IT ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.

        ë¬¸ì˜: {user_input}

        ë¶„ë¥˜: """

    result = chat.invoke(
        [
            SystemMessage(
                content="ë‹¹ì‹ ì€ IT í—¬í”„ë°ìŠ¤í¬ì˜ ë² í…Œë‘ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì •í™•í•œ ë¬¸ì œ ë¶„ë¥˜ì™€ ì¹œì ˆí•œ ê³ ê° ì‘ëŒ€ë¥¼ ë™ì‹œì— ìˆ˜í–‰í•©ë‹ˆë‹¤."
            ),
            HumanMessage(content=prompt),
        ]
    )

    classification = result.content.strip()

    # ë¶„ë¥˜ ê²°ê³¼ ì •ë¦¬
    if "existing" in classification:
        return "existing"
    elif "new" in classification:
        return "new"
    elif "skip" in classification:
        return "skip"
    else:
        return "skip"


def load_manual(db):
    with open("it_helpdesk_manual.json", "r", encoding="utf-8") as f:
        data = json.load(f)

    docs = []
    for item in data:
        doc = Document(
            page_content=item["text_content"],
            metadata={
                "id": item["id"],
                "category": item["metadata"]["category"],
                "scenario": item["metadata"]["scenario"],
                "keywords": ", ".join(item["metadata"]["keywords"]),
                "priority": item["metadata"]["priority"],
            },
        )
        docs.append(doc)

    # 2. ìŠ¹ì¸ëœ FAQë„ ë¡œë“œ
    if os.path.exists("approved_faqs.json"):
        try:
            with open("approved_faqs.json", "r", encoding="utf-8") as f:
                approved_faqs = json.load(f)

            for faq in approved_faqs:
                doc = Document(...)
                docs.append(doc)

            print(f"ìŠ¹ì¸ëœ FAQ {len(approved_faqs)}ê°œ ì¶”ê°€")

        except Exception as e:
            print(f"ìŠ¹ì¸ëœ FAQ ë¡œë“œ ì‹¤íŒ¨: {e}")
    else:
        print("ğŸ’¡ ìŠ¹ì¸ëœ FAQ íŒŒì¼ ì—†ìŒ")

    db.add_documents(docs)
    print(f"{len(docs)}ê°œ ë¬¸ì„œ ë²¡í„° DBì— ì¶”ê°€ ì™„ë£Œ")


def get_response(user_input, chat_history, api_key):
    classification = classify(user_input, api_key)

    if classification == "existing":
        return handle_existing(user_input, chat_history, api_key)
    elif classification == "new":
        return handle_new(user_input, chat_history, api_key)
    else:  # skip
        return handle_skip(user_input, api_key)


def handle_existing(user_input, chat_history, api_key):
    chat = ChatUpstage(api_key=api_key, model="solar-pro")
    embeddings = UpstageEmbeddings(api_key=api_key, model="solar-embedding-1-large")

    db = Chroma(persist_directory="chroma_db", embedding_function=embeddings)

    retriever = db.as_retriever(search_kwargs={"k": 3})

    # ì§ˆë¬¸ ì¬êµ¬ì„±
    ctx_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", "ì´ì „ ëŒ€í™”ë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•˜ì„¸ìš”."),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    hist_retriever = create_history_aware_retriever(chat, retriever, ctx_prompt)

    # ë‹µë³€ ìƒì„±
    qa_prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """IT í—¬í”„ë°ìŠ¤í¬ì…ë‹ˆë‹¤. 

                ê·œì¹™:
                1. ë§¤ë‰´ì–¼ ì •ë³´ë¥¼ í™œìš©í•´ì„œ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…
                2. í•´ê²° ë°©ë²•ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ
                3. ëª¨ë¥´ë©´ IT ê´€ë¦¬ì ì—°ê²° ì•ˆë‚´ (ë‚´ì„  1004)
                4. ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì–´ì¡° ìœ ì§€

                ì§€ì› ì˜ì—­: ë„¤íŠ¸ì›Œí¬, ê³„ì •, ì´ë©”ì¼, í•˜ë“œì›¨ì–´, ì†Œí”„íŠ¸ì›¨ì–´, ë³´ì•ˆ

                ì°¸ê³  ë§¤ë‰´ì–¼: {context}""",
            ),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    qa_chain = create_stuff_documents_chain(chat, qa_prompt)
    rag_chain = create_retrieval_chain(hist_retriever, qa_chain)

    # íˆìŠ¤í† ë¦¬ ë³€í™˜
    history = []
    for msg in chat_history:
        if msg["role"] == "user":
            history.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            history.append(AIMessage(content=msg["content"]))

    result = rag_chain.invoke({"input": user_input, "chat_history": history})
    return result["answer"]


def handle_new(user_input, chat_history, api_key):
    chat = ChatUpstage(api_key=api_key, model="solar-pro")

    # íˆìŠ¤í† ë¦¬ ë³€í™˜, 4ê°œê¹Œì§€ë§Œ
    history = []
    for msg in chat_history[-4:]:
        if msg["role"] == "user":
            history.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            history.append(AIMessage(content=msg["content"]))

    # ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """ë‹¹ì‹ ì€ IT í—¬í”„ë°ìŠ¤í¬ì˜ ë² í…Œë‘ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

                ì´ ì§ˆë¬¸ì€ ìƒˆë¡œìš´ ìœ í˜•ì˜ IT ë¬¸ì˜ë¡œ, ê¸°ì¡´ ë§¤ë‰´ì–¼ì— ì—†ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤.

                ë‹µë³€ ë°©ì‹:
                1. ê°€ëŠ¥í•œ ë²”ìœ„ì—ì„œ ë„ì›€ì´ ë  ë§Œí•œ ì •ë³´ ì œê³µ
                2. ìƒˆë¡œìš´ ê¸°ìˆ /ì •ì±…ì´ë¼ ì •ë³´ê°€ ì œí•œì ì¼ ìˆ˜ ìˆìŒì„ ì•ˆë‚´
                3. ë” ì •í™•í•œ ë‹µë³€ì„ ìœ„í•´ IT ê´€ë¦¬ì ì—°ê²° í•„ìš”í•¨ì„ ëª…ì‹œ
                4. ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡° ìœ ì§€

                ë‹µë³€ ë§ˆì§€ë§‰ì— í•­ìƒ ë‹¤ìŒ ë¬¸êµ¬ í¬í•¨:
                "ë” ì •í™•í•œ ì •ë³´ëŠ” IT ê´€ë¦¬ì(ë‚´ì„  1004)ì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
                """,
            ),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    # ë‹µë³€ ìƒì„±
    chain = prompt | chat
    result = chain.invoke({"input": user_input, "chat_history": history})

    # FAQ í›„ë³´ ìƒì„±
    faq_candidate = add_faq_candidate(user_input, result.content)

    # ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
    st.session_state.faq_candidates.append(faq_candidate)

    # íŒŒì¼ì— ì €ì¥
    save_faq_candidates(st.session_state.faq_candidates)

    # # FAQ í›„ë³´ ë“±ë¡
    # faq_candidate = {
    #     "question": user_input,
    #     "generated_answer": result.content,
    #     "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    #     "status": "pending_review",
    # }

    # # ì„¸ì…˜ ìƒíƒœì— FAQ í›„ë³´ ì €ì¥
    # if "faq_candidates" not in st.session_state:
    #     st.session_state.faq_candidates = []

    # st.session_state.faq_candidates.append(faq_candidate)

    print(
        f"""
FAQ í›„ë³´ ë“±ë¡ ì™„ë£Œ! (ì´ {len(st.session_state.faq_candidates)}ê°œ)
1. ì§ˆë¬¸: {faq_candidate['question']}
2. ì‹œê°„: {faq_candidate['timestamp']}
3. ë‹µë³€: {faq_candidate['generated_answer'][:100]}...
        """
    )

    return result.content


def handle_skip(user_input, api_key):
    user_lower = user_input.lower()

    # ì¸ì‚¬
    if any(keyword in user_lower for keyword in GREETING_KEYWORDS):
        return "ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š IT í—¬í”„ë°ìŠ¤í¬ì…ë‹ˆë‹¤. ì–´ë–¤ IT ë¬¸ì œë¡œ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"

    # ì¼ìƒ
    elif any(keyword in user_lower for keyword in CASUAL_KEYWORDS):
        return handle_casual_chat(user_input)

    # ë‹¤ë¥¸ ì—…ë¬´
    elif any(keyword in user_lower for keyword in OFFTOPIC_KEYWORDS):
        return """ì£„ì†¡í•˜ì§€ë§Œ IT ê´€ë ¨ ë¬¸ì˜ë§Œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ğŸ˜…
        
                í•´ë‹¹ ì—…ë¬´ëŠ” ë‹´ë‹¹ ë¶€ì„œì— ë¬¸ì˜í•´ì£¼ì„¸ìš”!
                IT ê´€ë ¨ ë¬¸ì œê°€ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš” ğŸ’»"""

    # ë§¤ì¹­ ì‹¤íŒ¨
    else:
        return """IT í—¬í”„ë°ìŠ¤í¬ì…ë‹ˆë‹¤! ğŸ˜Š 
        
                êµ¬ì²´ì ì¸ IT ë¬¸ì œë¥¼ ë§ì”€í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                ğŸŒ ë„¤íŠ¸ì›Œí¬, ğŸ” ê³„ì •, ğŸ“§ ì´ë©”ì¼, ğŸ–¨ï¸ í•˜ë“œì›¨ì–´, ğŸ’¿ ì†Œí”„íŠ¸ì›¨ì–´"""


def handle_casual_chat(user_input):
    """ì¼ìƒ ëŒ€í™”ì— ìœ„íŠ¸ ìˆê²Œ ì‘ë‹µ"""
    user_lower = user_input.lower()

    if any(word in user_lower for word in CASUAL_CHAT_KEYWORDS["weather"]):
        return "ì°½ë°– í™•ì¸ ëª»í–ˆì–´ìš” ğŸ˜… ëŒ€ì‹  ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœëŠ” í™•ì¸ ê°€ëŠ¥í•´ìš”!"

    elif any(word in user_lower for word in CASUAL_CHAT_KEYWORDS["food"]):
        return "ì €ëŠ” ì „ê¸°ë§Œ ë¨¹ê³  ì‚´ì•„ìš” ğŸ”Œ ì‹ì‚¬ ë“œì‹œê³  IT ë¬¸ì˜ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€!"

    elif any(word in user_lower for word in CASUAL_CHAT_KEYWORDS["tired"]):
        return "í˜ë“œì‹œê² ì–´ìš”! ê°„ë‹¨í•œ IT ì—…ë¬´ëŠ” ì œê°€ ë„ì™€ë“œë¦´ê²Œìš” ğŸ’ª"

    elif any(word in user_lower for word in CASUAL_CHAT_KEYWORDS["positive"]):
        return "IT ë¬¸ì œ í•´ê²°ë„ ì¬ë°Œì–´ìš”! ğŸ˜„ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"

    elif any(word in user_lower for word in CASUAL_CHAT_KEYWORDS["thanks"]):
        return "ì²œë§Œì—ìš”! ğŸ˜Š ì¶”ê°€ IT ë¬¸ì˜ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ì£¼ì„¸ìš”!"

    else:
        return "í¥ë¯¸ë¡œìš´ ì´ì•¼ê¸°ë„¤ìš”! ğŸ˜Š ê·¸ëŸ°ë° IT ê´€ë ¨ ë¬¸ì œëŠ” ì—†ìœ¼ì‹ ê°€ìš”?"


def init_faq_system():
    if "faq_candidates" not in st.session_state:
        st.session_state.faq_candidates = load_faq_candidates()
    return True


@st.cache_resource
def init_db():
    """ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ëŠ” DB ì´ˆê¸°í™”"""
    api_key = os.getenv("UPSTAGE_API_KEY")
    if not api_key:
        print("API KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    embeddings = UpstageEmbeddings(api_key=api_key, model="solar-embedding-1-large")
    db = Chroma(persist_directory="chroma_db", embedding_function=embeddings)

    if db._collection.count() == 0:
        load_manual(db)
        print("âœ… ë§¤ë‰´ì–¼ ë¡œë”© ì™„ë£Œ!")
    else:
        print("âœ… ê¸°ì¡´ ë§¤ë‰´ì–¼ ë°ì´í„° ë¡œë”© ì™„ë£Œ")

    return db


# UI ì‹œì‘ ë¶€ë¶„
st.set_page_config(page_title="IT í—¬í”„ë°ìŠ¤í¬", page_icon="ğŸ’»")

if "messages" not in st.session_state:
    st.session_state.messages = []

if "api_key" not in st.session_state:
    st.session_state.api_key = os.getenv("UPSTAGE_API_KEY")

if st.session_state.api_key:
    db = init_db()
    init_faq_system()
    if db is None:
        st.error("ë§¤ë‰´ì–¼ ë¡œë”© ì‹¤íŒ¨")

st.title("ğŸ’» IT í—¬í”„ë°ìŠ¤í¬")

if not st.session_state.api_key:
    st.warning("API í‚¤ í•„ìš”")
    api_key = st.text_input("API í‚¤:", type="password")
    if api_key:
        st.session_state.api_key = api_key
        st.rerun()

# ì²« ì¸ì‚¬ ë©”ì‹œì§€
if not st.session_state.messages:
    greeting = """IT í—¬í”„ë°ìŠ¤í¬ì…ë‹ˆë‹¤. ğŸ’»

    ì§€ì› ê°€ëŠ¥:
    ğŸŒ ë„¤íŠ¸ì›Œí¬ (ì™€ì´íŒŒì´, VPN)
    ğŸ” ê³„ì •/ë¡œê·¸ì¸
    ğŸ“§ ì´ë©”ì¼/ì—…ë¬´ì‹œìŠ¤í…œ
    ğŸ–¨ï¸ í•˜ë“œì›¨ì–´
    ğŸ’¿ ì†Œí”„íŠ¸ì›¨ì–´
    ğŸ›¡ï¸ ë³´ì•ˆ

    ë¬¸ì œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”."""

    st.session_state.messages.append({"role": "assistant", "content": greeting})

# ì±„íŒ… ë¶€ë¶„
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ë¬¸ì œ ì„¤ëª…"):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response = get_response(
            prompt, st.session_state.messages[:-1], st.session_state.api_key
        )
        st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})
